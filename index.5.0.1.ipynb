{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smpF-KqtFDDF",
        "outputId": "8b0914ee-09f1-4661-f7de-2258a6eef1bc"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cloner174/mr.Sina.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fbKpdt0FFgo",
        "outputId": "ce1c639b-9f6e-4e01-9115-7afd7bb00032"
      },
      "outputs": [],
      "source": [
        "%cd mr.Sina"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKtN_PC6E-6_"
      },
      "outputs": [],
      "source": [
        "# Import Packages :\n",
        "\n",
        "import pandas as pd\n",
        "from main import DataHandle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zjSDQEpE-7H",
        "outputId": "10595059-91da-4529-c1e1-d7b6a9c234f9"
      },
      "outputs": [],
      "source": [
        "# Loading data\n",
        "\n",
        "data = pd.read_csv( 'input/link_dataFinal.csv' , index_col=0)\n",
        "nodes = pd.read_csv( './input/nodes.csv' )\n",
        "\n",
        "print(data.shape, nodes.shape)\n",
        "#((969395, 3), (8977, 5))\n",
        "data = data.sample(frac=0.01)\n",
        "nodes_list = []\n",
        "sors = []\n",
        "advs = []\n",
        "pubs = []\n",
        "for i in data['source'] :\n",
        "  if i in nodes['id'].tolist():\n",
        "    if i not in nodes_list:\n",
        "      sors.append(i)\n",
        "      nodes_list.append(i)\n",
        "      index = nodes.index[nodes['id'] == i].tolist()[0]\n",
        "      if list(nodes.iloc[[index]]['color'] == 'red')[0]:\n",
        "        advs.append(i)\n",
        "      else:\n",
        "        pubs.append(i)\n",
        "tar = []\n",
        "for i in data['target'] :\n",
        "  if i in nodes['id'].tolist():\n",
        "    if i not in nodes_list:\n",
        "      tar.append(i)\n",
        "      nodes_list.append(i)\n",
        "      index = nodes.index[nodes['id'] == i].tolist()[0]\n",
        "      if list(nodes.iloc[[index]]['color'] == 'red')[0]:\n",
        "        advs.append(i)\n",
        "      else:\n",
        "        pubs.append(i)\n",
        "\n",
        "advs_ = list(set(advs))\n",
        "pubs_ = list(set(pubs))\n",
        "len(advs_), len(pubs_) #(4299, 1946)\n",
        "len(nodes_list)# تعداد کل نود ها 6245"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmbvdsCrE-7I",
        "outputId": "d1c74147-178a-4417-917b-faf33262a90b"
      },
      "outputs": [],
      "source": [
        "# Finding the nodes from data to pass to the DataHandel class!\n",
        "\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVE82K6pE-7I"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv( 'input/links.csv' , index_col=0)\n",
        "\n",
        "data = data.sample(frac=1, random_state=32)\n",
        "\n",
        "links_ = []\n",
        "sources_ = []\n",
        "targets_ = []\n",
        "for i in range(data.shape[0]) :\n",
        "    sor_ = data.loc[i, 'source']\n",
        "    tar_ = data.loc[i, 'target']\n",
        "    if sor_ in nodes_list and tar_ in nodes_list:\n",
        "        sources_.append(sor_)\n",
        "        targets_.append(tar_)\n",
        "        links_.append( (sor_, tar_) )\n",
        "        if len(links_) == 60000 :\n",
        "            break\n",
        "        else:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw2a8sN0IVyN",
        "outputId": "300f341d-2a2f-4c01-f239-002f81bc45f3"
      },
      "outputs": [],
      "source": [
        "len(links_) # تعداد کل لینک ها 199981"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "nodes_list = []\n",
        "sors = []\n",
        "advs = []\n",
        "pubs = []\n",
        "for i in data['source'] :\n",
        "  if i in nodes['id'].tolist():\n",
        "    if i not in nodes_list:\n",
        "      sors.append(i)\n",
        "      nodes_list.append(i)\n",
        "      index = nodes.index[nodes['id'] == i].tolist()[0]\n",
        "      if list(nodes.iloc[[index]]['color'] == 'red')[0]:\n",
        "        advs.append(i)\n",
        "      else:\n",
        "        pubs.append(i)\n",
        "tar = []\n",
        "for i in data['target'] :\n",
        "  if i in nodes['id'].tolist():\n",
        "    if i not in nodes_list:\n",
        "      tar.append(i)\n",
        "      nodes_list.append(i)\n",
        "      index = nodes.index[nodes['id'] == i].tolist()[0]\n",
        "      if list(nodes.iloc[[index]]['color'] == 'red')[0]:\n",
        "        advs.append(i)\n",
        "      else:\n",
        "        pubs.append(i)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CigYJ0XMZYzH"
      },
      "outputs": [],
      "source": [
        "advs_ = list(set(advs))\n",
        "pubs_ = list(set(pubs))\n",
        "\n",
        "#len(advs_), len(pubs_) #(4299, 1946)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrt8lj70Ikxg"
      },
      "outputs": [],
      "source": [
        "name_laybel1 = [ 'a_node' for i in range( len(advs ))]\n",
        "name_laybel2 = [ 'p_node' for i in range( len(pubs ))]\n",
        "name_laybel = name_laybel1.copy()\n",
        "name_laybel.extend(name_laybel2)\n",
        "id_laybel = advs.copy()\n",
        "id_laybel.extend(pubs)\n",
        "nodes = {\n",
        "    'name' : name_laybel,\n",
        "    'id' : id_laybel\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQYGw7EaIZU_"
      },
      "outputs": [],
      "source": [
        "links = {\n",
        "    'source' : sources_,\n",
        "    'target' : targets_\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQYJgK2lI99o"
      },
      "outputs": [],
      "source": [
        "# getting data ready by turnnig to dicts both !\n",
        "print(type(nodes), type(links))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnCvO8VOSZcx"
      },
      "outputs": [],
      "source": [
        "# This will prepare and preprocess the data :\n",
        "\n",
        "Start = DataHandle( data_links= links, data_nodes= nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fou4nmcBKtwG",
        "outputId": "97bde145-4b8c-4f12-84f5-f90bd8017dd2"
      },
      "outputs": [],
      "source": [
        "Start.initial_keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7gdIhs8R376",
        "outputId": "d85008df-26e0-4945-8359-7526182633d0"
      },
      "outputs": [],
      "source": [
        "layer_one_links, layer_two_links, interconnected_links = Start.modify_links()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print( 'داده استفاده شده برای ترین وتست - لایه اول لینک ها', len(layer_one_links))\n",
        "print( 'داده استفاده شده برای ترین وتست - لایه دوم لینک ها', len(layer_two_links))\n",
        "print( 'داده استفاده شده برای ترین وتست -بین لایه ای لینک ها', len(interconnected_links))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "داده ی اولیه !!\n",
        "\n",
        "داده استفاده شده برای ترین وتست - لایه اول لینک ها 31570\n",
        "\n",
        "داده استفاده شده برای ترین وتست - لایه دوم لینک ها 137300\n",
        "\n",
        "داده استفاده شده برای ترین وتست -بین لایه ای لینک ها 31111\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdJaz0pTE-7N",
        "outputId": "f763b6a0-d52b-4ea5-f632-a70d0c1c9b5a"
      },
      "outputs": [],
      "source": [
        "print( 'داده استفاده شده برای ترین وتست - نود ها ادورتایزرز', len(advs))\n",
        "print( 'داده استفاده شده برای ترین وتست - نود ها پابلیشرز', len(pubs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lfjVZYwE-7P"
      },
      "outputs": [],
      "source": [
        "from main import graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZScEWQJ8E-7P"
      },
      "outputs": [],
      "source": [
        "G = graph.Graph(layer_one_name= 'Advertisers', layer_two_name= 'Publishers', nx_use = True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSbbJPiSE-7Q"
      },
      "outputs": [],
      "source": [
        "# This is another use of add_links method for simple data :\n",
        "G_test, G_train , g_nx = G.add_links( layer_one_links = layer_one_links ,\n",
        "                                               layer_two_links = layer_two_links ,\n",
        "                                               Interconnected_links = interconnected_links,\n",
        "                                      layer_one_nodes = advs,\n",
        "                                      layer_two_nodes = pubs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQqSdKT9Wivu",
        "outputId": "a0754498-abbc-41ae-a379-c7321aa15946"
      },
      "outputs": [],
      "source": [
        "print(' گراف برای تست ', G_test)\n",
        "print(' گراف برای ترین' , G_train)\n",
        "print( ' گراف برای ارزیابی نهایی ', g_nx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-K2-MsnbPhT"
      },
      "outputs": [],
      "source": [
        "# گراف برای تست  Graph with 3723 nodes and 14987 edges\n",
        " #گراف برای ترین Graph with 1740 nodes and 67272 edges\n",
        " # گراف برای ارزیابی نهایی  Graph with 5463 nodes and 95553 edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Z_XgebxXPMh"
      },
      "outputs": [],
      "source": [
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "gAsF7kuLvhgF",
        "outputId": "22b29f0e-5e2d-46e7-c230-1a8b5687bc7b"
      },
      "outputs": [],
      "source": [
        "# Helper function to create feature set for Logistic Regression\n",
        "def create_features(graph, edge_list):\n",
        "    # Feature dictionary\n",
        "    features = {\n",
        "        'common_neighbors': [],\n",
        "        'jaccard_coefficient': [],\n",
        "        'preferential_attachment': []\n",
        "    }\n",
        "    labels = []\n",
        "\n",
        "    for u, v in edge_list:\n",
        "        # Common Neighbors\n",
        "        common_neighbors = list(nx.common_neighbors(graph, u, v))\n",
        "        features['common_neighbors'].append(len(common_neighbors))\n",
        "\n",
        "        # Jaccard Coefficient\n",
        "        jaccard_coeff = list(nx.jaccard_coefficient(graph, [(u, v)]))[0][2]\n",
        "        features['jaccard_coefficient'].append(jaccard_coeff)\n",
        "\n",
        "        # Preferential Attachment\n",
        "        pref_attach = graph.degree(u) * graph.degree(v)\n",
        "        features['preferential_attachment'].append(pref_attach)\n",
        "\n",
        "        # Label (1 if edge exists, 0 otherwise)\n",
        "        labels.append(1 if graph.has_edge(u, v) else 0)\n",
        "\n",
        "    # Create DataFrame\n",
        "    feature_df = pd.DataFrame(features)\n",
        "    return feature_df, labels\n",
        "\n",
        "# Create features and labels for training and test data\n",
        "train_features, train_labels = create_features(G_train, list(G_train.edges) + list(nx.non_edges(G_train)))\n",
        "test_features, test_labels = create_features(G_test, list(G_test.edges) + list(nx.non_edges(G_test)))\n",
        "\n",
        "\n",
        "\n",
        "print( 'گراف تمرین - تعداد نمونه ها ' ,len(train_labels) )\n",
        "print('')\n",
        "\n",
        "print( ' گراف تست - تعداد نمونه ها', len(test_labels) )\n",
        "print('')\n",
        "train_features.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39OXq0kewSN2",
        "outputId": "bea6f50c-0647-4089-e29d-e48d96b52c8d"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "logistic_model.fit(train_features, train_labels)\n",
        "\n",
        "# Predict on the test set\n",
        "test_predictions = logistic_model.predict(test_features)\n",
        "test_probabilities = logistic_model.predict_proba(test_features)[:, 1]\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(test_labels, test_predictions)\n",
        "\n",
        "# Recall (Sensitivity)\n",
        "recall = recall_score(test_labels, test_predictions)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(test_labels, test_predictions)\n",
        "\n",
        "# ROC AUC Score (if y_pred contains probabilities)\n",
        "roc_auc = roc_auc_score(test_labels, test_predictions)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC Score:\", roc_auc)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQuB9t8WwmM5"
      },
      "outputs": [],
      "source": [
        "new_test_features, new_test_labels = create_features(g_nx, list(g_nx.edges) + list(nx.non_edges(g_nx)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9_Mmix7yvmp"
      },
      "outputs": [],
      "source": [
        "new_test_predictions = logistic_model.predict(new_test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE2gPQFTyvUZ",
        "outputId": "9f2a209d-694b-4556-a8d8-a44acf25acb9"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "accuracy = accuracy_score(new_test_labels, new_test_predictions)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(new_test_labels, new_test_predictions)\n",
        "\n",
        "# Recall (Sensitivity)\n",
        "recall = recall_score(new_test_labels, new_test_predictions)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(new_test_labels, new_test_predictions)\n",
        "\n",
        "# ROC AUC Score (if y_pred contains probabilities)\n",
        "roc_auc = roc_auc_score(new_test_labels, new_test_predictions)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(new_test_labels, new_test_predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC Score:\", roc_auc)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5wBOlj9E-7S"
      },
      "outputs": [],
      "source": [
        "# Centrality Measures :\n",
        "\n",
        "def calculate_centrality_measures(G):\n",
        "    degree_centrality = nx.degree_centrality(G)\n",
        "    betweenness_centrality = nx.betweenness_centrality(G)\n",
        "    closeness_centrality = nx.closeness_centrality(G)\n",
        "    return degree_centrality, betweenness_centrality, closeness_centrality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "YKuJKpFfXC_u",
        "outputId": "249d37c0-abb8-41d2-e50b-9b41f7980905"
      },
      "outputs": [],
      "source": [
        "degree_centrality = nx.degree_centrality(G_train)\n",
        "closeness_centrality = nx.closeness_centrality(G_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogoEK-kGXBQ9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "degree_values = list(degree_centrality.values())\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(degree_values, bins = 20, kde=True, color='blue')\n",
        "plt.title('Degree Centrality Distribution G_train')\n",
        "plt.xlabel('Centrality')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "closeness_values = list(closeness_centrality.values())\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(closeness_values, kde=True, color='red')\n",
        "plt.title('Closeness Centrality Distribution G_train')\n",
        "plt.xlabel('Centrality')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBEHScSjYDM4"
      },
      "outputs": [],
      "source": [
        "degree_centrality = nx.degree_centrality(G_test)\n",
        "closeness_centrality = nx.closeness_centrality(G_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vb-X-du8YDFc",
        "outputId": "90b60346-6598-400d-d930-2194b0ae5aeb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "degree_values = list(degree_centrality.values())\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(degree_values, bins = 20, kde=True, color='blue')\n",
        "plt.title('Degree Centrality Distribution G_test')\n",
        "plt.xlabel('Centrality')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "closeness_values = list(closeness_centrality.values())\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(closeness_values, kde=True, color='red')\n",
        "plt.title('Closeness Centrality Distribution G_test')\n",
        "plt.xlabel('Centrality')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "bww67I8UYUNH",
        "outputId": "5b499b0a-e650-4d6d-f5d9-0e49a797e792"
      },
      "outputs": [],
      "source": [
        "degree_centrality = nx.degree_centrality(g_nx)\n",
        "closeness_centrality = nx.closeness_centrality(g_nx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85oFg_MvYUGv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "degree_values = list(degree_centrality.values())\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(degree_values, bins = 20, kde=True, color='blue')\n",
        "plt.title('Degree Centrality Distribution G_between_layers')\n",
        "plt.xlabel('Centrality')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "closeness_values = list(closeness_centrality.values())\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(closeness_values, kde=True, color='red')\n",
        "plt.title('Closeness Centrality Distribution G_between_layers')\n",
        "plt.xlabel('Centrality')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ابتدا سری به روش جنگل تصادفی میزنیم چون با استخراج ویژگی های عددی الان یک پیش بینی پیژگی محور محض را داریم\\\\\n",
        "\n",
        "باید حلقه ی ویژگی ها ۳ بار تککرار شود\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP42BhCfzYOY"
      },
      "outputs": [],
      "source": [
        "G = G_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qj3HcuvbZLAh"
      },
      "outputs": [],
      "source": [
        "G = G_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOSy2VdZZMZv"
      },
      "outputs": [],
      "source": [
        "G = g_nx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "jzx5OD13E-7T",
        "outputId": "0fc39064-dfea-459b-d89e-1506e59248e6"
      },
      "outputs": [],
      "source": [
        "\n",
        "from itertools import combinations\n",
        "\n",
        "# Graph\n",
        "degree_centrality, betweenness_centrality, closeness_centrality = calculate_centrality_measures(G)\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "# Calculating features for each pair of nodes:\n",
        "for node1, node2 in combinations(G.nodes(), 2):\n",
        "\n",
        "    # Centrality measures for node1 and node2\n",
        "    degree_centrality_1 = degree_centrality[node1]\n",
        "    degree_centrality_2 = degree_centrality[node2]\n",
        "    betweenness_centrality_1 = betweenness_centrality[node1]\n",
        "    betweenness_centrality_2 = betweenness_centrality[node2]\n",
        "    closeness_centrality_1 = closeness_centrality[node1]\n",
        "    closeness_centrality_2 = closeness_centrality[node2]\n",
        "\n",
        "    # Directly compute and append features\n",
        "    features.append((\n",
        "        node1,\n",
        "        node2,\n",
        "        len(list(nx.common_neighbors(G, node1, node2))),  # Common Neighbors\n",
        "        next(nx.preferential_attachment(G, [(node1, node2)]))[2],  # Preferential Attachment\n",
        "        next(nx.resource_allocation_index(G, [(node1, node2)]))[2],  # Resource Allocation\n",
        "        next(nx.adamic_adar_index(G, [(node1, node2)]))[2],  # Adamic Adar\n",
        "        next(nx.jaccard_coefficient(G, [(node1, node2)]))[2] , # Jaccard Coefficient\n",
        "        (degree_centrality_1 + degree_centrality_2) / 2,\n",
        "        (betweenness_centrality_1 + betweenness_centrality_2) / 2,\n",
        "        (closeness_centrality_1 + closeness_centrality_2) / 2\n",
        "    ))\n",
        "\n",
        "    # Existence of links between nodes (1 or 0)\n",
        "    labels.append(1 if G.has_edge(node1, node2) else 0)\n",
        "\n",
        "# Creating a DataFrame from the features and labels\n",
        "features_df = pd.DataFrame(features,\n",
        "                           columns=['node1','node2','Common Neighbors',\n",
        "                                    'Preferential Attachment', 'Resource Allocation',\n",
        "                                    'Adamic Adar', 'Jaccard Coefficient', 'Average Degree Centrality',\n",
        "                                    'Average Betweenness Centrality', 'Average Closeness Centrality'])\n",
        "\n",
        "features_df['Label'] = labels\n",
        "\n",
        "# Now features_df is ready to use in a machine learning model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YHHStpnZHmI"
      },
      "outputs": [],
      "source": [
        "features_df.to_csv('G-Layer1-dataframe.csv', index=False,\n",
        "                   compression = {'method': 'zip', 'compresslevel': 1 } )\n",
        "\n",
        "# This furtehr can be loaded using compression='zip' !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP9rwMyaZOxv"
      },
      "outputs": [],
      "source": [
        "features_df.to_csv('G-Layer2-dataframe.csv', index=False, \n",
        "                   compression = {'method': 'zip', 'compresslevel': 1 } )\n",
        "# This furtehr can be loaded using compression='zip' !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKQHosczFoFA"
      },
      "outputs": [],
      "source": [
        "features_df.to_csv('G-inBetweenLayers-dataframe3.csv', index=False, \n",
        "                   compression = {'method': 'zip', 'compresslevel': 8 } )\n",
        "# This furtehr can be loaded using compression='zip' !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkkGd02liVGA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE76UeXLQofN",
        "outputId": "f4b1f7e0-d4e7-4b8b-94ac-7a9bc4d8f33f"
      },
      "outputs": [],
      "source": [
        "%cd ./mr.Sina"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOquIo31E-7T"
      },
      "outputs": [],
      "source": [
        "data1 = pd.read_csv('./G-Layer1-dataframe.csv', compression='zip')\n",
        "data2 = pd.read_csv('./G-Layer2-dataframe.csv', compression='zip')\n",
        "data3 = pd.read_csv('./G-inBetweenLayers-dataframe.csv', compression='zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf6PjYJpGCQQ"
      },
      "outputs": [],
      "source": [
        "y1 = data1['Label']  # Labels\n",
        "X1 = data1.drop(['node1','node2','Label'], axis=1)  # Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5Wnj33K0mB-"
      },
      "outputs": [],
      "source": [
        "y2 = data2['Label']  # Labels\n",
        "X2 = data2.drop(['node1','node2','Label'], axis=1)  # Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxK5b9tW0l7U"
      },
      "outputs": [],
      "source": [
        "X3 = data3.drop(['node1','node2','Label'], axis=1)  # Features\n",
        "y3 = data3['Label']  # Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGOgVm2WGDz3"
      },
      "outputs": [],
      "source": [
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGdJofLs0XPr"
      },
      "outputs": [],
      "source": [
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiZSNNPG0h6x"
      },
      "outputs": [],
      "source": [
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pKOF3kGlsem",
        "outputId": "cac84e11-0eaa-4fa9-8f6d-a5c0aba61b43"
      },
      "outputs": [],
      "source": [
        "#X_train1.shape, X_train2.shape, X_train3.shape, y_train1.shape, y_train2.shape, y_test3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_ = np.concatenate((X_train1, X_train2, X_train3))\n",
        "y_train_ = np.concatenate((y_train1, y_train2, y_train3))\n",
        "\n",
        "X_test_ = np.concatenate((X_test1, X_test2, X_test3))\n",
        "y_test_ = np.concatenate((y_test1, y_test2, y_test3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFI9skbBE-7Z",
        "outputId": "131a6d99-f495-49b2-d346-c5e6f52f9e1f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "# Prepare data\n",
        "X = np.array(X_train_)\n",
        "y = np.array(y_train_)\n",
        "\n",
        "# model :\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=8, verbose = 1)\n",
        "\n",
        "# Stratified K-Fold\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=8)\n",
        "\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train model\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Predict probabilities\n",
        "    probabilities = clf.predict_proba(X_test)[:, 1]\n",
        "    predict = clf.predict(X_test)\n",
        "\n",
        "    predictions = probabilities.astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision, recall, fscore, _ = precision_recall_fscore_support(y_test, predictions, average='binary')\n",
        "    accuracy = accuracy_score(y_test, predict)\n",
        "    print(f\"Average Accuracy: {accuracy}\")\n",
        "    print(f\"Average Precision: {precision}\")\n",
        "    print(f\"Average Recall: {recall}\")\n",
        "    print(f\"Average F1-Score: {fscore}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtFYrYYRm8Ll"
      },
      "outputs": [],
      "source": [
        "# unseen Data :\n",
        "\n",
        "predict_ = clf.predict(X_test_)\n",
        "predict_prob = clf.predict_proba(X_test_)[:, 1]\n",
        "predict_prob = predict_prob.astype(int)\n",
        "\n",
        "accuracy_ = accuracy_score(y_test_, predict_)\n",
        "precision, recall, fscore, _ = precision_recall_fscore_support(y_test_, predict_prob, average='binary')\n",
        "\n",
        "print(f\"Average Accuracy: {accuracy_}\")\n",
        "print(f\"Average Precision: {precision}\")\n",
        "print(f\"Average Recall: {recall}\")\n",
        "print(f\"Average F1-Score: {fscore}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "confuse_matrix = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "ConfusionMatrixDisplay.from_predictions(y_test_, predict_)\n",
        "plt.title('Confusion Matrix for Model Predictions X_test1')\n",
        "plt.show()\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC Score:\", roc_auc)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test_, predict_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([-0.01, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic y_test1 VS test_probabilities1')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_, predict_)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_test_, predict_prob)\n",
        "\n",
        "# Recall (Sensitivity)\n",
        "recall = recall_score(y_test_, predict_prob)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_test_, predict_prob)\n",
        "\n",
        "# ROC AUC Score (if y_pred contains probabilities)\n",
        "roc_auc = roc_auc_score(y_test_, predict_prob)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test_, predict_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhSRXlB512bY",
        "outputId": "5e219835-8610-4028-efee-641c2adae85f"
      },
      "outputs": [],
      "source": [
        "# Creating DataFrame\n",
        "X_test_results_df = pd.DataFrame({\n",
        "    'Actual from X_test': y_test_,\n",
        "    'Predicted from X_test': predict_,\n",
        "\n",
        "\n",
        "})\n",
        "\n",
        "X_test_results_df_prob = pd.DataFrame({\n",
        "    'Actual from X_test': y_test_,\n",
        "    'Predicted Prob from X_test': predict_prob,\n",
        "})\n",
        "\n",
        "# Saving DataFrame to CSV\n",
        "csv_path = 'X_test_results_df.csv'\n",
        "X_test_results_df.to_csv(csv_path, index=False)\n",
        "\n",
        "csv_path = 'X_test_results_df_prob.csv'\n",
        "X_test_results_df_prob.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"Saved predictions and actual labels\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0Tb1p7sE-7Z"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix Guide :\n",
        "#    [ [TN    FP]\n",
        "#      [FN    TP] ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuBev6uOtEWe"
      },
      "outputs": [],
      "source": [
        "#%pip install torch_geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xx9h6Vg8fSH"
      },
      "source": [
        "بگذارید رگرسیون را تست کنیم"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1s4r7M9u9RX1"
      },
      "outputs": [],
      "source": [
        "# data1 = train, data2 = train , data3 = test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grd60ns79Cg6"
      },
      "outputs": [],
      "source": [
        "X_train1 = data1.drop(['node1','node2','Label'], axis=1)  # Features\n",
        "y_train1 = data1['Label']  # Labels\n",
        "\n",
        "X_train2 = data2.drop(['node1','node2','Label'], axis=1)  # Features\n",
        "y_train2 = data2['Label']  # Labels\n",
        "\n",
        "X_test = data3.drop(['node1','node2','Label'], axis=1)  # Features\n",
        "y_test = data3['Label']  # Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = np.concatenate((X_train1, X_train2, X_train3))\n",
        "y_train = np.concatenate((y_train1, y_train2, y_train3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi0XEbN-87MN"
      },
      "outputs": [],
      "source": [
        "train_features = X_train\n",
        "train_labels = y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "5sCPiToc8jj5",
        "outputId": "26448c4a-3673-4172-e919-19a50a22a6cc"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "logistic_model = LogisticRegression(random_state=64, max_iter=1000)\n",
        "logistic_model.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtwMQlbj9xEP"
      },
      "outputs": [],
      "source": [
        "X_test = np.concatenate((X_test1, X_test2, X_test3))\n",
        "y_test = np.concatenate((y_test1, y_test2, y_test3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQAtX__V92Il"
      },
      "outputs": [],
      "source": [
        "# Now the completly new and unseen :\n",
        "test_features = X_test\n",
        "test_labels = y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on the test set\n",
        "test_predictions = logistic_model.predict(test_features)\n",
        "test_probabilities = logistic_model.predict_proba(test_features)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A3KTbQp96BF"
      },
      "outputs": [],
      "source": [
        "# Calculate metrics\n",
        "roc_auc = roc_auc_score(test_labels, test_probabilities)\n",
        "accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "roc_auc, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(test_labels, test_predictions)\n",
        "\n",
        "# Recall (Sensitivity)\n",
        "recall = recall_score(test_labels, test_predictions)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(test_labels, test_predictions)\n",
        "\n",
        "# ROC AUC Score (if y_pred contains probabilities)\n",
        "roc_auc = roc_auc_score(test_labels, test_probabilities)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC Score:\", roc_auc)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "Jh08yUOhcDAu",
        "outputId": "e93c6bdd-8e1e-4b08-9ab1-28d3edc9a5ef"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "fpr, tpr, _ = roc_curve(test_labels, test_probabilities)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([-0.01, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic ->LogisticRegression<- ')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxcO1smXcC0n"
      },
      "outputs": [],
      "source": [
        "data1 = pd.read_csv('./G-Layer1-dataframe.csv', compression='zip')\n",
        "data2 = pd.read_csv('./G-Layer2-dataframe.csv', compression='zip')\n",
        "data3 = pd.read_csv('./G-inBetweenLayers-dataframe.csv', compression='zip')\n",
        "y1 = data1['Label']  # Labels\n",
        "X1 = data1.drop(['node1','node2','Label'], axis=1)  # Features\n",
        "y2 = data2['Label']  # Labels\n",
        "X2 = data2.drop(['node1','node2','Label'], axis=1)  # Features\n",
        "X3 = data3.drop(['node1','node2','Label'], axis=1)  # Features\n",
        "y3 = data3['Label']  # Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=16)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=16)\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.2, random_state=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_ = np.concatenate((X_train1, X_train2, X_train3))\n",
        "y_train_ = np.concatenate((y_train1, y_train2, y_train3))\n",
        "\n",
        "X_test_ = np.concatenate((X_test1, X_test2, X_test3))\n",
        "y_test_ = np.concatenate((y_test1, y_test2, y_test3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urPXq-FTerjI",
        "outputId": "c5e90336-9198-4530-ea72-29bab078faeb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [20, 30],  # Number of trees in the forest\n",
        "    'max_depth': [100, 200, 300],  # Maximum depth of the tree\n",
        "    'min_samples_split': [50, 100]   # Minimum number of samples required to split an internal node\n",
        "}\n",
        "\n",
        "# Initialize the classifier\n",
        "rf = RandomForestClassifier(random_state=32)\n",
        "\n",
        "# Create the grid search object\n",
        "scorer = make_scorer(accuracy_score)\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, scoring=scorer, cv=5)\n",
        "\n",
        "# Fit grid search to the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_, y_train_, test_size=0.2, random_state=32)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
        "\n",
        "# Use the best parameters to make predictions\n",
        "best_clf = grid_search.best_estimator_\n",
        "predictions = best_clf.predict(X_test_)\n",
        "print(\"Test Accuracy: \", accuracy_score(y_test_, predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ww1IEeGfpAy"
      },
      "outputs": [],
      "source": [
        "predictions = best_clf.predict(X_test_)\n",
        "probabilities = best_clf.predict_proba(X_test_)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOhAG1UjhFvj",
        "outputId": "e4d4faef-76c6-420c-890d-a2b45e86f153"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_, test_predictions)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_test_, test_predictions)\n",
        "\n",
        "# Recall (Sensitivity)\n",
        "recall = recall_score(y_test_, test_predictions)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(y_test_, test_predictions)\n",
        "\n",
        "# ROC AUC Score (if y_pred contains probabilities)\n",
        "roc_auc = roc_auc_score(y_test_, test_probabilities)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test_, test_predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"ROC AUC Score:\", roc_auc)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "hHthIorthsUZ",
        "outputId": "5516e670-d11d-414f-90c5-60f47690f57b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvBs7jk7Do8b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".gragh",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
